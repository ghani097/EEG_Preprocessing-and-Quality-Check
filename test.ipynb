{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#install ASR artifact rejection\n",
    "!pip install asrpy -q\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#importing all requirements\n",
    "\n",
    "import mne\n",
    "from mne.datasets import ssvep\n",
    "from asrpy import ASR\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import os\n",
    "%matplotlib inline\n",
    "from mne_icalabel import label_components\n",
    "from mne.preprocessing import ICA\n",
    "from mne import export\n",
    "from scipy.stats import linregress\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the path where the data is secured\n",
    "\n",
    "path = r'C:\\Users\\PC1\\Documents\\MATLAB\\test' # use your path\n",
    "all_files = glob.glob(os.path.join(path, \"*.set\")) \n",
    "output_folder = 'processed'\n",
    "os.makedirs(output_folder, exist_ok=True)  # Create folder if it doesn't exist\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to contain all the code which runs all preprocessing steps and then call PSD function for the quality check\n",
    "\n",
    "\n",
    "\n",
    "for filename in all_files:\n",
    "    raw = mne.io.read_raw_eeglab(filename, preload=True)\n",
    "    print(filename)\n",
    "    \n",
    "    # Select EEG channels\n",
    "    picks = mne.pick_types(raw.info, meg=False, eeg=True, stim=False, eog=False)\n",
    "    raw.pick(picks)\n",
    "\n",
    "    # Set EEG reference and apply filters\n",
    "    raw.set_eeg_reference(\"average\")\n",
    "    raw.filter(l_freq=1., h_freq=100.)\n",
    "    raw.notch_filter(freqs=[60])  # Bandstop for power grid\n",
    "\n",
    "    # Make a copy of uncleaned data\n",
    "    raw_uncleaned = raw.copy()\n",
    "\n",
    "    # Apply ASR\n",
    "    asr = ASR(sfreq=raw.info[\"sfreq\"], cutoff=15)\n",
    "    asr.fit(raw)\n",
    "    CleanData = asr.transform(raw)\n",
    "\n",
    "    # Initialize and fit ICA with extended infomax\n",
    "    ica = ICA(method='infomax', fit_params=dict(extended=True), random_state=97)\n",
    "    ica.fit(CleanData)\n",
    "\n",
    "    # Label components and exclude those with brain label and proba <= 0.8\n",
    "    IC_COMP = label_components(CleanData, ica, method='iclabel')\n",
    "    indices = [i for i, (proba, label) in enumerate(zip(IC_COMP['y_pred_proba'], IC_COMP['labels']))\n",
    "               if label == 'brain' and proba <= 0.8]\n",
    "    ica.exclude.extend(indices)\n",
    "\n",
    "    # Apply ICA to CleanData\n",
    "    CleanData = ica.apply(CleanData)\n",
    "\n",
    "    # Generate a unique output filename based on the original filename\n",
    "    base_name = os.path.splitext(os.path.basename(filename))[0]  # Get base name without extension\n",
    "    output_filename = os.path.join(output_folder, f\"{base_name}_processed.set\")\n",
    "\n",
    "    # Save each processed file to the \"processed\" folder\n",
    "    export.export_raw(output_filename, CleanData, fmt='eeglab', overwrite=True)\n",
    "    print(f\"Saved: {output_filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CleanData.plot()\n",
    "events = mne.events_from_annotations(CleanData)\n",
    "\n",
    "# Check the event IDs\n",
    "print(events[1]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing Boundary events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get current annotations\n",
    "annotations = CleanData.annotations\n",
    "\n",
    "# Filter out annotations labeled as 'BAD boundary'\n",
    "filtered_annotations = annotations[annotations.description != 'boundary']\n",
    "\n",
    "# Replace the annotations in the CleanData object\n",
    "CleanData.set_annotations(filtered_annotations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_duration = 2.0  # seconds\n",
    "step_size = 1.0        # seconds\n",
    "# Total recording time\n",
    "recording_duration = CleanData.times[-1]\n",
    "\n",
    "# Create overlapping windows\n",
    "start_times = []\n",
    "t = 0.0\n",
    "while t + window_duration <= recording_duration:\n",
    "    start_times.append(t)\n",
    "    t += step_size\n",
    "\n",
    "print(f\"Number of windows: {len(start_times)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Extract data for each window\n",
    "epochs_data = []\n",
    "for start_time in start_times:\n",
    "    stop_time = start_time + window_duration\n",
    "    epochs_data.append(CleanData.copy().crop(tmin=start_time, tmax=stop_time).get_data())\n",
    "\n",
    "# Convert to MNE Epochs object\n",
    "info = CleanData.info  # Use the same info as the CleanData object\n",
    "epochs = mne.EpochsArray(data=np.array(epochs_data), info=info)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Label all pseudo-epochs as \"resting\" (label = 1)\n",
    "event_ids = {'rest': 1}\n",
    "events = np.array([[int(start_time * CleanData.info['sfreq']), 0, 1] for start_time in start_times])\n",
    "\n",
    "# Use events to create epochs\n",
    "epochs = mne.Epochs(CleanData, events, event_id=event_ids, tmin=0, tmax=window_duration,\n",
    "                    baseline=None, detrend=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CleanData.plot()\n",
    "epochs.plot()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SOURCE LOCALIZATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Forward Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Key \"SUBJECTS_DIR\" not found in the environment or in the the mne-python config file (C:\\\\Users\\\\PC1\\\\.mne\\\\mne-python.json). Try either os.environ[\"SUBJECTS_DIR\"] = VALUE for a temporary solution, or mne.utils.set_config(\"SUBJECTS_DIR\", VALUE, set_env=True) for a permanent one. You can also set the environment variable before running python.'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmne\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m make_bem_model, make_bem_solution, setup_source_space, make_forward_solution\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# BEM model\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m bem_model \u001b[38;5;241m=\u001b[39m \u001b[43mmake_bem_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubject\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msubject_name\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconductivity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0.3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mico\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m bem_solution \u001b[38;5;241m=\u001b[39m make_bem_solution(bem_model)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Source space\u001b[39;00m\n",
      "File \u001b[1;32m<decorator-gen-109>:12\u001b[0m, in \u001b[0;36mmake_bem_model\u001b[1;34m(subject, ico, conductivity, subjects_dir, verbose)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\PC1\\mne-python\\1.8.0_0\\Lib\\site-packages\\mne\\bem.py:686\u001b[0m, in \u001b[0;36mmake_bem_model\u001b[1;34m(subject, ico, conductivity, subjects_dir, verbose)\u001b[0m\n\u001b[0;32m    682\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m conductivity\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m conductivity\u001b[38;5;241m.\u001b[39msize \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m):\n\u001b[0;32m    683\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    684\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconductivity must be a float or a 1D array-like with 1 or 3 elements\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    685\u001b[0m     )\n\u001b[1;32m--> 686\u001b[0m subjects_dir \u001b[38;5;241m=\u001b[39m \u001b[43mget_subjects_dir\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubjects_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mraise_error\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    687\u001b[0m subject_dir \u001b[38;5;241m=\u001b[39m subjects_dir \u001b[38;5;241m/\u001b[39m subject\n\u001b[0;32m    688\u001b[0m bem_dir \u001b[38;5;241m=\u001b[39m subject_dir \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbem\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\PC1\\mne-python\\1.8.0_0\\Lib\\site-packages\\mne\\utils\\config.py:471\u001b[0m, in \u001b[0;36mget_subjects_dir\u001b[1;34m(subjects_dir, raise_error)\u001b[0m\n\u001b[0;32m    469\u001b[0m from_config \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    470\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m subjects_dir \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 471\u001b[0m     subjects_dir \u001b[38;5;241m=\u001b[39m \u001b[43mget_config\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mSUBJECTS_DIR\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mraise_error\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mraise_error\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    472\u001b[0m     from_config \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    473\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m subjects_dir \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\PC1\\mne-python\\1.8.0_0\\Lib\\site-packages\\mne\\utils\\config.py:329\u001b[0m, in \u001b[0;36mget_config\u001b[1;34m(key, default, raise_error, home_dir, use_env)\u001b[0m\n\u001b[0;32m    321\u001b[0m     extra_env \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    322\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m You can also set the environment variable before running python.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    323\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m use_env\n\u001b[0;32m    324\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    325\u001b[0m     )\n\u001b[0;32m    326\u001b[0m     meth_file \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    327\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmne.utils.set_config(\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, VALUE, set_env=True) for a permanent one\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    328\u001b[0m     )\n\u001b[1;32m--> 329\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\n\u001b[0;32m    330\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mKey \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m not found in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloc_env\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    331\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe mne-python config file (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m). \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    332\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTry \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmeth_env\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mmeth_file\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mextra_env\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    333\u001b[0m     )\n\u001b[0;32m    334\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    335\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m config\u001b[38;5;241m.\u001b[39mget(key, default)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Key \"SUBJECTS_DIR\" not found in the environment or in the the mne-python config file (C:\\\\Users\\\\PC1\\\\.mne\\\\mne-python.json). Try either os.environ[\"SUBJECTS_DIR\"] = VALUE for a temporary solution, or mne.utils.set_config(\"SUBJECTS_DIR\", VALUE, set_env=True) for a permanent one. You can also set the environment variable before running python.'"
     ]
    }
   ],
   "source": [
    "from mne import make_bem_model, make_bem_solution, setup_source_space, make_forward_solution\n",
    "\n",
    "# BEM model\n",
    "bem_model = make_bem_model(subject='subject_name', conductivity=[0.3], ico=4)\n",
    "bem_solution = make_bem_solution(bem_model)\n",
    "\n",
    "# Source space\n",
    "src = setup_source_space(subject='subject_name', spacing='oct6', \n",
    "                         subjects_dir='/path/to/freesurfer/subjects')\n",
    "\n",
    "# Forward solution\n",
    "fwd = make_forward_solution(epochs.info, trans='subject_name-trans.fif', \n",
    "                            src=src, bem=bem_solution, eeg=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Noise COV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mne import compute_covariance\n",
    "\n",
    "# Estimate noise covariance\n",
    "noise_cov = compute_covariance(epochs, tmax=0., method='auto')  # Use baseline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inverse Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mne.minimum_norm import make_inverse_operator, apply_inverse\n",
    "\n",
    "# Create the inverse operator\n",
    "inverse_operator = make_inverse_operator(epochs.info, fwd, noise_cov, loose=0.2, depth=0.8)\n",
    "\n",
    "# Apply inverse solution to epochs\n",
    "stc = apply_inverse(epochs.average(), inverse_operator, lambda2=1/9., method='dSPM')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mne.time_frequency import tfr_multitaper, tfr_morlet\n",
    "\n",
    "# Define frequencies of interest\n",
    "frequencies = np.arange(1, 40, 1)  # 1-40 Hz\n",
    "n_cycles = frequencies / 2.0       # Number of cycles, adaptable to frequency\n",
    "\n",
    "# Morlet wavelet\n",
    "tfr = tfr_morlet(epochs, freqs=frequencies, n_cycles=n_cycles, \n",
    "                 use_fft=True, return_itc=False, decim=3, average=True)\n",
    "\n",
    "# Plot TFR for a single channel\n",
    "tfr.plot([0], baseline=(-0.5, 0), mode='logratio', title='TFR for Channel 0')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mne.time_frequency import tfr_multitaper\n",
    "\n",
    "# Define frequencies of interest\n",
    "frequencies = np.arange(1, 40, 1)  # 1-40 Hz\n",
    "\n",
    "# Define the number of cycles for each frequency\n",
    "n_cycles = frequencies / 2.0  # Adjust as needed (e.g., cycles = frequency / 2)\n",
    "\n",
    "# Multitaper Time-Frequency Analysis\n",
    "tfr_mt = tfr_multitaper(epochs, freqs=frequencies, n_cycles=n_cycles,\n",
    "                        time_bandwidth=4.0, return_itc=False, average=True)\n",
    "\n",
    "# Plot TFR for a single channel\n",
    "tfr_mt.plot([1], baseline=(-0.5, 0), mode='logratio', title='Multitaper TFR')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PSD_CHECK()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#Quality check function on the processed data \n",
    "\n",
    "# Define the folder where processed files are saved\n",
    "def PSD_CHECK():\n",
    " processed_folder = 'processed'\n",
    "\n",
    "  # Get a list of all .set files in the processed folder\n",
    " processed_files = [os.path.join(processed_folder, f) for f in os.listdir(processed_folder) if f.endswith('.set')]\n",
    "\n",
    " # Loop through each processed file and calculate the PSD\n",
    " for processed_file in processed_files:\n",
    "    # Read the processed .set file\n",
    "    raw = mne.io.read_raw_eeglab(processed_file, preload=True)\n",
    "    print(f\"Calculating PSD for {processed_file}\")\n",
    "    psd_data = raw.compute_psd(fmin=1, fmax=80)\n",
    "    psd, freqs = psd_data.get_data(return_freqs=True)\n",
    "    # Plot the PSD similar to MNE's style\n",
    "    # Convert PSD to dB scale\n",
    "    psd_db = 10 * np.log10(psd.mean(axis=0))  # Mean across channels\n",
    "\n",
    "    # Choose the frequency range to fit (e.g., from 1 Hz to 80 Hz)\n",
    "    freq_range = (freqs >= 1) & (freqs <= 80)  # Boolean mask for selected frequencies\n",
    "    freqs_selected = freqs[freq_range]\n",
    "    psd_db_selected = psd_db[freq_range]\n",
    "\n",
    "    # Fit a linear regression line to the selected frequency range\n",
    "    slope, intercept, r_value, p_value, std_err = linregress(freqs_selected, psd_db_selected)\n",
    "    # Data quality assessment based on slope\n",
    "    if slope >= 0:\n",
    "     quality = \"Garbage\"\n",
    "    elif 0 > slope >= -0.1:\n",
    "     quality = \"Poor\"\n",
    "    elif -0.1 > slope >= -0.2:\n",
    "     quality = \"Fair\"\n",
    "    elif -0.2 > slope >= -0.3:\n",
    "     quality = \"Good\"\n",
    "    else:  # slope < -0.3\n",
    "     quality = \"Excellent\"\n",
    "\n",
    "    print(f\"Data Quality: {quality}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
